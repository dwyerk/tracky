input {
  file {
    path => "/takeout/Location History/Location History.json"
#    path => "/takeout/Location History/location-short.json"
    mode => "read"
    file_completed_action => "log"
    file_completed_log_path => "/takeout/ingest.log"
    codec => multiline {
      pattern => "^  }, {"
      negate => true
      what => "previous"
      max_lines => 20000
    }
  }
}

filter {
  mutate {
    gsub => [
      "message", "^{\n  \"locations\" : \[", "", # Fix the first record
      "message", "^  },", "", # Fix the trailing curly brace from the previous record
      "message", "^    } ]$", "    } ]}", # add the missing curly that got eaten by the multiline codec
      "message", "ccuracy\" : ([0-9]+)$", "ccuracy\" : \1 }",
      "message", "heading\" : ([0-9]+)$", "heading\" : \1 }",
      "message", "velocity\" : ([0-9]+)$", "velocity\" : \1 }",
      "message", "altitude\" : ([-0-9]+)$", "altitude\" : \1 }",
      "message", "^  } ]$", "",
      "message", "^}$", "" # Fix the final mismatched curly
    ]
  }
  json {
    source => "message"
    remove_field => "message"
    remove_field => "path"
    remove_field => "host"
  }
  date {
    match => [ "timestampMs", "UNIX_MS" ]
  }
  ruby {
    code => "
      event.set('latitude', event.get('latitudeE7') / 10000000.0)
      event.set('longitude', event.get('longitudeE7') / 10000000.0)
      event.set('point', [event.get('longitude'), event.get('latitude')])
      "
  }
}

#output {
#  file {
#    path => "/takeout/test.log"
#  }
#}

output {
  elasticsearch {
    index => "history-%{+YYYY}"
    template => "/takeout/mappings/history.json"
    template_name => "history"
    hosts => ["http://es01:9200", "http://es02:9200"]
    document_id => "%{timestampMs}"
  }
}
